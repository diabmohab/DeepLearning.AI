{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12090
        },
        "outputId": "b880603f-a641-4751-8f74-88e3e2449f8d"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-23 07:24:32--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.128.128, 2a00:1450:4013:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.128.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  52.4MB/s    in 1.6s    \n",
            "\n",
            "2019-05-23 07:24:34 (52.4 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd69477f-0b82-4f1a-8d48-b00210391866"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8908
        },
        "outputId": "3b7b6da8-d47c-4019-bdaa-77e39971b5b7"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "133f4c3c-f472-4d87-df5f-7205009d1dbf"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-23 07:26:25--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 2a00:1450:4013:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  47.8MB/s    in 3.0s    \n",
            "\n",
            "2019-05-23 07:26:28 (47.8 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-23 07:26:30--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 2a00:1450:4013:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  39.8MB/s    in 0.3s    \n",
            "\n",
            "2019-05-23 07:26:31 (39.8 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4b43061a-b3c2-4c8f-d43b-0fecd37528f6"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3ff45802-9c5a-47bc-e23d-ea0884907404"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        },
        "outputId": "b2827cbe-a461-4db3-ba93-6134e240ee9f"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 4s 282ms/step - loss: 0.0056 - acc: 0.9961\n",
            " - 22s - loss: 0.3051 - acc: 0.8783 - val_loss: 0.0056 - val_acc: 0.9961\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 178ms/step - loss: 0.0574 - acc: 0.9766\n",
            " - 16s - loss: 0.0985 - acc: 0.9649 - val_loss: 0.0574 - val_acc: 0.9766\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 3.3497e-04 - acc: 1.0000\n",
            " - 18s - loss: 0.0564 - acc: 0.9796 - val_loss: 3.3497e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 0.0323 - acc: 0.9883\n",
            " - 17s - loss: 0.0607 - acc: 0.9815 - val_loss: 0.0323 - val_acc: 0.9883\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 173ms/step - loss: 4.6188e-04 - acc: 1.0000\n",
            " - 17s - loss: 0.0338 - acc: 0.9893 - val_loss: 4.6188e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 0.0173 - acc: 0.9922\n",
            " - 18s - loss: 0.1002 - acc: 0.9757 - val_loss: 0.0173 - val_acc: 0.9922\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 186ms/step - loss: 0.1815 - acc: 0.9727\n",
            " - 20s - loss: 0.0351 - acc: 0.9864 - val_loss: 0.1815 - val_acc: 0.9727\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 0.0786 - acc: 0.9844\n",
            " - 16s - loss: 0.0365 - acc: 0.9912 - val_loss: 0.0786 - val_acc: 0.9844\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 158ms/step - loss: 0.1654 - acc: 0.9727\n",
            " - 17s - loss: 0.0505 - acc: 0.9873 - val_loss: 0.1654 - val_acc: 0.9727\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.1905 - acc: 0.9727\n",
            " - 18s - loss: 0.0323 - acc: 0.9873 - val_loss: 0.1905 - val_acc: 0.9727\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 170ms/step - loss: 0.0310 - acc: 0.9883\n",
            " - 17s - loss: 0.0421 - acc: 0.9834 - val_loss: 0.0310 - val_acc: 0.9883\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 0.0154 - acc: 0.9922\n",
            " - 16s - loss: 0.0301 - acc: 0.9883 - val_loss: 0.0154 - val_acc: 0.9922\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 158ms/step - loss: 0.0479 - acc: 0.9922\n",
            " - 16s - loss: 0.0320 - acc: 0.9903 - val_loss: 0.0479 - val_acc: 0.9922\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.0318 - acc: 0.9922\n",
            " - 17s - loss: 0.0312 - acc: 0.9883 - val_loss: 0.0318 - val_acc: 0.9922\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 2s 182ms/step - loss: 0.1435 - acc: 0.9805\n",
            " - 18s - loss: 0.0216 - acc: 0.9932 - val_loss: 0.1435 - val_acc: 0.9805\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.2395 - acc: 0.9648\n",
            " - 17s - loss: 0.0212 - acc: 0.9932 - val_loss: 0.2395 - val_acc: 0.9648\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 0.4171 - acc: 0.9492\n",
            " - 16s - loss: 0.0159 - acc: 0.9942 - val_loss: 0.4171 - val_acc: 0.9492\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 174ms/step - loss: 0.1643 - acc: 0.9727\n",
            " - 17s - loss: 0.0211 - acc: 0.9932 - val_loss: 0.1643 - val_acc: 0.9727\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: 0.5821 - acc: 0.9492\n",
            " - 16s - loss: 0.0190 - acc: 0.9951 - val_loss: 0.5821 - val_acc: 0.9492\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 0.2186 - acc: 0.9648\n",
            " - 18s - loss: 0.0247 - acc: 0.9903 - val_loss: 0.2186 - val_acc: 0.9648\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 170ms/step - loss: 0.1179 - acc: 0.9844\n",
            " - 18s - loss: 0.0293 - acc: 0.9883 - val_loss: 0.1179 - val_acc: 0.9844\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.2013 - acc: 0.9648\n",
            " - 16s - loss: 0.0411 - acc: 0.9893 - val_loss: 0.2013 - val_acc: 0.9648\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 2s 144ms/step - loss: 0.0910 - acc: 0.9922\n",
            " - 16s - loss: 0.0221 - acc: 0.9932 - val_loss: 0.0910 - val_acc: 0.9922\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 2s 174ms/step - loss: 0.3339 - acc: 0.9570\n",
            " - 16s - loss: 0.0260 - acc: 0.9912 - val_loss: 0.3339 - val_acc: 0.9570\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 182ms/step - loss: 0.3282 - acc: 0.9531\n",
            " - 22s - loss: 0.0197 - acc: 0.9922 - val_loss: 0.3282 - val_acc: 0.9531\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.2646 - acc: 0.9648\n",
            " - 17s - loss: 0.0217 - acc: 0.9912 - val_loss: 0.2646 - val_acc: 0.9648\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 163ms/step - loss: 0.4263 - acc: 0.9570\n",
            " - 17s - loss: 0.0112 - acc: 0.9942 - val_loss: 0.4263 - val_acc: 0.9570\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 0.2647 - acc: 0.9648\n",
            " - 17s - loss: 0.0183 - acc: 0.9961 - val_loss: 0.2647 - val_acc: 0.9648\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 2s 177ms/step - loss: 0.3731 - acc: 0.9531\n",
            " - 18s - loss: 0.0147 - acc: 0.9942 - val_loss: 0.3731 - val_acc: 0.9531\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 0.2077 - acc: 0.9688\n",
            " - 17s - loss: 0.0161 - acc: 0.9961 - val_loss: 0.2077 - val_acc: 0.9688\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 2s 176ms/step - loss: 0.1851 - acc: 0.9727\n",
            " - 17s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.1851 - val_acc: 0.9727\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 172ms/step - loss: 0.1127 - acc: 0.9922\n",
            " - 17s - loss: 0.0238 - acc: 0.9922 - val_loss: 0.1127 - val_acc: 0.9922\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 0.1221 - acc: 0.9883\n",
            " - 17s - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1221 - val_acc: 0.9883\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 0.1274 - acc: 0.9844\n",
            " - 18s - loss: 0.0288 - acc: 0.9932 - val_loss: 0.1274 - val_acc: 0.9844\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.3337 - acc: 0.9570\n",
            " - 16s - loss: 0.0191 - acc: 0.9932 - val_loss: 0.3337 - val_acc: 0.9570\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 172ms/step - loss: 0.1399 - acc: 0.9805\n",
            " - 17s - loss: 0.0167 - acc: 0.9961 - val_loss: 0.1399 - val_acc: 0.9805\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: 0.3955 - acc: 0.9531\n",
            " - 17s - loss: 0.0309 - acc: 0.9932 - val_loss: 0.3955 - val_acc: 0.9531\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.1121 - acc: 0.9922\n",
            " - 16s - loss: 0.0167 - acc: 0.9942 - val_loss: 0.1121 - val_acc: 0.9922\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.1649 - acc: 0.9727\n",
            " - 19s - loss: 0.0163 - acc: 0.9942 - val_loss: 0.1649 - val_acc: 0.9727\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.2190 - acc: 0.9766\n",
            " - 16s - loss: 0.0497 - acc: 0.9922 - val_loss: 0.2190 - val_acc: 0.9766\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: 0.3871 - acc: 0.9570\n",
            " - 17s - loss: 0.0141 - acc: 0.9932 - val_loss: 0.3871 - val_acc: 0.9570\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 0.2732 - acc: 0.9609\n",
            " - 16s - loss: 0.0168 - acc: 0.9981 - val_loss: 0.2732 - val_acc: 0.9609\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.1820 - acc: 0.9766\n",
            " - 21s - loss: 0.0072 - acc: 0.9951 - val_loss: 0.1820 - val_acc: 0.9766\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 2s 172ms/step - loss: 0.3087 - acc: 0.9648\n",
            " - 18s - loss: 0.0130 - acc: 0.9961 - val_loss: 0.3087 - val_acc: 0.9648\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: 0.1340 - acc: 0.9805\n",
            " - 17s - loss: 0.0387 - acc: 0.9942 - val_loss: 0.1340 - val_acc: 0.9805\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 0.4790 - acc: 0.9531\n",
            " - 17s - loss: 0.0161 - acc: 0.9942 - val_loss: 0.4790 - val_acc: 0.9531\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 2s 158ms/step - loss: 0.1953 - acc: 0.9805\n",
            " - 16s - loss: 0.0416 - acc: 0.9903 - val_loss: 0.1953 - val_acc: 0.9805\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.3133 - acc: 0.9648\n",
            " - 18s - loss: 0.0159 - acc: 0.9951 - val_loss: 0.3133 - val_acc: 0.9648\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 2s 175ms/step - loss: 0.1981 - acc: 0.9805\n",
            " - 17s - loss: 0.0110 - acc: 0.9961 - val_loss: 0.1981 - val_acc: 0.9805\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 2s 163ms/step - loss: 0.2858 - acc: 0.9648\n",
            " - 17s - loss: 0.0220 - acc: 0.9951 - val_loss: 0.2858 - val_acc: 0.9648\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 0.3944 - acc: 0.9609\n",
            " - 16s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.3944 - val_acc: 0.9609\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 2s 172ms/step - loss: 0.2725 - acc: 0.9727\n",
            " - 17s - loss: 0.0076 - acc: 0.9971 - val_loss: 0.2725 - val_acc: 0.9727\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 2s 157ms/step - loss: 0.3520 - acc: 0.9570\n",
            " - 18s - loss: 0.0337 - acc: 0.9942 - val_loss: 0.3520 - val_acc: 0.9570\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 2s 153ms/step - loss: 0.1604 - acc: 0.9805\n",
            " - 16s - loss: 0.0156 - acc: 0.9942 - val_loss: 0.1604 - val_acc: 0.9805\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.1394 - acc: 0.9805\n",
            " - 16s - loss: 0.0181 - acc: 0.9951 - val_loss: 0.1394 - val_acc: 0.9805\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.2899 - acc: 0.9688\n",
            " - 17s - loss: 0.0237 - acc: 0.9932 - val_loss: 0.2899 - val_acc: 0.9688\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 3s 197ms/step - loss: 0.3212 - acc: 0.9648\n",
            " - 18s - loss: 0.0128 - acc: 0.9981 - val_loss: 0.3212 - val_acc: 0.9648\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 0.3069 - acc: 0.9609\n",
            " - 17s - loss: 0.0072 - acc: 0.9971 - val_loss: 0.3069 - val_acc: 0.9609\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: 0.3143 - acc: 0.9648\n",
            " - 17s - loss: 0.0189 - acc: 0.9961 - val_loss: 0.3143 - val_acc: 0.9648\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 0.3247 - acc: 0.9609\n",
            " - 16s - loss: 0.0073 - acc: 0.9961 - val_loss: 0.3247 - val_acc: 0.9609\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 2s 184ms/step - loss: 0.3925 - acc: 0.9531\n",
            " - 19s - loss: 0.0059 - acc: 0.9961 - val_loss: 0.3925 - val_acc: 0.9531\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 2s 155ms/step - loss: 0.4307 - acc: 0.9531\n",
            " - 19s - loss: 0.0304 - acc: 0.9942 - val_loss: 0.4307 - val_acc: 0.9531\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 3s 203ms/step - loss: 0.3028 - acc: 0.9648\n",
            " - 17s - loss: 0.0120 - acc: 0.9951 - val_loss: 0.3028 - val_acc: 0.9648\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 0.1772 - acc: 0.9805\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 17s - loss: 0.0028 - acc: 0.9990 - val_loss: 0.1772 - val_acc: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "c095cdb7-0250-45d3-bf9c-408f4c2b5d2c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCR9h5JfmEwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}